{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_on_CIFR_Assignment_updated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK3alCdFflQX"
      },
      "source": [
        "### CNN on CIFR Assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHCYMwwXflQd"
      },
      "source": [
        "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
        "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
        "3.  You cannot use DropOut layers.\n",
        "4.  You MUST use Image Augmentation Techniques.\n",
        "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "7.  You cannot use test images for training the model.\n",
        "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "10. You cannot have more than 1 Million parameters in total\n",
        "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
        "12. You can use any optimization algorithm you need. \n",
        "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLVcyNYKflQi"
      },
      "source": [
        "### Let's import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8enUEwZCzN5e"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tensorflow.keras import models,layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler,CSVLogger, Callback,ReduceLROnPlateau"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RUVOKDfzN5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e742bf5-cc44-4755-fbee-c0f7430e513c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0n-AFKIvIKY",
        "outputId": "0cc307a2-0f75-4c63-a004-e84af05d3638"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive',force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSp7J4bFzN5f"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 250\n",
        "l = 12\n",
        "num_filter = 36\n",
        "compression = 0.5\n",
        "dropout_rate = 0\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT-LVDFqzN5f",
        "outputId": "ed0dd8ec-cf66-45d8-9185-212096d81dba"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height,img_width,channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "print(img_height)\n",
        "print(img_width)\n",
        "print(channel)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n",
            "32\n",
            "32\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ_-Ns2EzN5g",
        "outputId": "d2392fcf-761f-4d01-b5b7-0af495a0a904"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJY7cFJ_zN5g"
      },
      "source": [
        "#convert to one hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NJhpCQYzN5h",
        "outputId": "082104ca-4d4d-47eb-cb05-82ddc3dcf84c"
      },
      "source": [
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQtFjcnzN5h",
        "outputId": "c1b7ae84-67d4-4820-d637-8615fdac1a84"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWBfiLODzN5i"
      },
      "source": [
        "### Model with Dense Block, Transition and Output blocks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiy92DmecZhe"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp  = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8JDqqS-NFC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173aec21-7ef6-478d-fb3b-e7223d11be60"
      },
      "source": [
        "num_filter = 36\n",
        "l = 12\n",
        "dropout_rate = 0\n",
        "\n",
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter,(3,3),activation ='relu',use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model.summary()\n",
        "          "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 36)   972         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 36)   144         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 36)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 18)   5832        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 54)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 18)   8748        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 72)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 72)   288         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 72)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 18)   11664       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 90)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 90)   360         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 90)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 18)   14580       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 108)  0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 108)  432         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 108)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 18)   17496       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 126)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 126)  504         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 126)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 18)   20412       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 144)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 144)  576         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 144)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 18)   23328       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 162)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 162)  648         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 162)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 18)   26244       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 180)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 180)  720         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 180)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 18)   29160       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 198)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 198)  792         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 198)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 18)   32076       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 216)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 216)  864         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 216)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 18)   34992       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 234)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 234)  936         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 234)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 18)   37908       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 252)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 252)  1008        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 252)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 18)   4536        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 18)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 18)   72          average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 18)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 18)   2916        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 36)   0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 36)   144         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 36)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 18)   5832        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 16, 16, 54)   0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 54)   216         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 54)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 18)   8748        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 16, 16, 72)   0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 72)   288         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 72)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 18)   11664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 16, 16, 90)   0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 90)   360         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 90)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 18)   14580       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 108)  0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 108)  432         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 108)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 18)   17496       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 126)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 126)  504         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 126)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 18)   20412       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 144)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 18)   23328       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 162)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 162)  648         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 162)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 18)   26244       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 180)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 180)  720         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 180)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 18)   29160       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 198)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 198)  792         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 198)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 18)   32076       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 216)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 216)  864         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 216)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 18)   34992       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 234)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 234)  936         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 234)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 18)   4212        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 18)     0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 18)     72          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 18)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 18)     2916        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 36)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 36)     144         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 36)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 18)     5832        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 8, 8, 54)     0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 54)     216         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 54)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 18)     8748        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 8, 8, 72)     0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 72)     288         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 72)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 18)     11664       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 90)     0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 90)     360         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 90)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 18)     14580       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 8, 8, 108)    0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 108)    432         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 108)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 18)     17496       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 8, 8, 126)    0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 126)    504         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 126)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 18)     20412       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 8, 8, 144)    0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 144)    576         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 144)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 18)     23328       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 162)    0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 162)    648         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 162)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 18)     26244       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 180)    0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 180)    720         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 180)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 18)     29160       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 198)    0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 198)    792         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 198)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 18)     32076       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 216)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 216)    864         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 216)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 18)     34992       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 234)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 234)    936         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 234)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 18)     4212        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 18)     0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 18)     72          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 18)     0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 18)     2916        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 4, 4, 36)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 36)     144         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 36)     0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 18)     5832        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 4, 4, 54)     0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 54)     216         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 54)     0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 18)     8748        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 4, 4, 72)     0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 72)     288         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 72)     0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 18)     11664       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 4, 4, 90)     0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 90)     360         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 90)     0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 18)     14580       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 4, 4, 108)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 108)    432         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 108)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 18)     17496       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 4, 4, 126)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 126)    504         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 126)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 18)     20412       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 4, 4, 144)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 144)    576         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 144)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 18)     23328       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 4, 4, 162)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 162)    648         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 162)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 18)     26244       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 4, 4, 180)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 180)    720         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 180)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 18)     29160       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 4, 4, 198)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 198)    792         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 198)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 18)     32076       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 4, 4, 216)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 216)    864         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 216)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 18)     34992       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 4, 4, 234)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 234)    936         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 234)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 234)    0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 936)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           9370        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 995,230\n",
            "Trainable params: 981,658\n",
            "Non-trainable params: 13,572\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMO7o5P-ofrH"
      },
      "source": [
        "**Image Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKZHx3vcM0JM"
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=15,horizontal_flip=True,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=15)\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyQGEzlLzXjM"
      },
      "source": [
        "checkpoint = ModelCheckpoint('gdrive/My Drive/cnnoncifar/cifar10_model_save/model-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5',\n",
        "                                       monitor='val_accuracy')\n",
        "\n",
        "csvlog = CSVLogger('gdrive/My Drive/cnnoncifar/csvlog.h5', append = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJvSaI4p0w2R"
      },
      "source": [
        "model.compile(loss= \"categorical_crossentropy\",optimizer=SGD(0.1,momentum = 0.7),metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHbPoV-ZlhFk",
        "outputId": "c45d9ef6-82c8-474c-953c-8335d1ce2316"
      },
      "source": [
        "\n",
        "path = 'gdrive/My Drive/cnnoncifar/'\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size), steps_per_epoch = x_train.shape[0]/batch_size, \n",
        "                    epochs = 30, validation_data =(x_test, y_test), callbacks = [checkpoint,csvlog])\n",
        "model.save_weights(os.path.join(path, '30epochs.h5'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "390/390 [==============================] - 251s 545ms/step - loss: 1.8326 - accuracy: 0.3547 - val_loss: 1.8010 - val_accuracy: 0.3592\n",
            "Epoch 2/30\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 1.4308 - accuracy: 0.4819 - val_loss: 1.3470 - val_accuracy: 0.5154\n",
            "Epoch 3/30\n",
            "390/390 [==============================] - 206s 526ms/step - loss: 1.2324 - accuracy: 0.5565 - val_loss: 1.4475 - val_accuracy: 0.5375\n",
            "Epoch 4/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 1.0704 - accuracy: 0.6174 - val_loss: 1.0906 - val_accuracy: 0.6205\n",
            "Epoch 5/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.9534 - accuracy: 0.6629 - val_loss: 1.1539 - val_accuracy: 0.6232\n",
            "Epoch 6/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.8611 - accuracy: 0.6962 - val_loss: 1.1443 - val_accuracy: 0.6244\n",
            "Epoch 7/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.7931 - accuracy: 0.7219 - val_loss: 0.8913 - val_accuracy: 0.6984\n",
            "Epoch 8/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.7388 - accuracy: 0.7381 - val_loss: 0.9972 - val_accuracy: 0.6862\n",
            "Epoch 9/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.6878 - accuracy: 0.7569 - val_loss: 1.3510 - val_accuracy: 0.6267\n",
            "Epoch 10/30\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 0.6525 - accuracy: 0.7713 - val_loss: 1.0587 - val_accuracy: 0.6746\n",
            "Epoch 11/30\n",
            "390/390 [==============================] - 211s 540ms/step - loss: 0.6180 - accuracy: 0.7843 - val_loss: 0.7362 - val_accuracy: 0.7469\n",
            "Epoch 12/30\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 0.5882 - accuracy: 0.7936 - val_loss: 0.6735 - val_accuracy: 0.7752\n",
            "Epoch 13/30\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.5646 - accuracy: 0.8017 - val_loss: 0.6184 - val_accuracy: 0.7900\n",
            "Epoch 14/30\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 0.5453 - accuracy: 0.8090 - val_loss: 0.7838 - val_accuracy: 0.7582\n",
            "Epoch 15/30\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.5230 - accuracy: 0.8180 - val_loss: 0.6884 - val_accuracy: 0.7769\n",
            "Epoch 16/30\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 0.5081 - accuracy: 0.8224 - val_loss: 0.6058 - val_accuracy: 0.7987\n",
            "Epoch 17/30\n",
            "390/390 [==============================] - 205s 525ms/step - loss: 0.4831 - accuracy: 0.8308 - val_loss: 0.5384 - val_accuracy: 0.8203\n",
            "Epoch 18/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.4688 - accuracy: 0.8366 - val_loss: 0.4834 - val_accuracy: 0.8315\n",
            "Epoch 19/30\n",
            "390/390 [==============================] - 206s 526ms/step - loss: 0.4539 - accuracy: 0.8423 - val_loss: 0.5028 - val_accuracy: 0.8315\n",
            "Epoch 20/30\n",
            "390/390 [==============================] - 206s 527ms/step - loss: 0.4444 - accuracy: 0.8451 - val_loss: 0.5023 - val_accuracy: 0.8356\n",
            "Epoch 21/30\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.4307 - accuracy: 0.8510 - val_loss: 0.6200 - val_accuracy: 0.8125\n",
            "Epoch 22/30\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.4147 - accuracy: 0.8546 - val_loss: 0.5028 - val_accuracy: 0.8345\n",
            "Epoch 23/30\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.4071 - accuracy: 0.8576 - val_loss: 0.4947 - val_accuracy: 0.8331\n",
            "Epoch 24/30\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3948 - accuracy: 0.8626 - val_loss: 0.5093 - val_accuracy: 0.8371\n",
            "Epoch 25/30\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3889 - accuracy: 0.8647 - val_loss: 0.4296 - val_accuracy: 0.8558\n",
            "Epoch 26/30\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3801 - accuracy: 0.8690 - val_loss: 0.5406 - val_accuracy: 0.8243\n",
            "Epoch 27/30\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3682 - accuracy: 0.8715 - val_loss: 0.5834 - val_accuracy: 0.8229\n",
            "Epoch 28/30\n",
            "390/390 [==============================] - 211s 539ms/step - loss: 0.3587 - accuracy: 0.8752 - val_loss: 0.5762 - val_accuracy: 0.8197\n",
            "Epoch 29/30\n",
            "390/390 [==============================] - 205s 526ms/step - loss: 0.3500 - accuracy: 0.8776 - val_loss: 0.5836 - val_accuracy: 0.8196\n",
            "Epoch 30/30\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.3424 - accuracy: 0.8792 - val_loss: 0.4844 - val_accuracy: 0.8401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxJ0PrPsxvkn",
        "outputId": "f05377e5-868d-448d-d00f-d3bd5565cd90"
      },
      "source": [
        "model.load_weights('/content/gdrive/MyDrive/cnnoncifar/cifar10_model_save/model-030-0.879160-0.840100.h5') \n",
        "path = 'gdrive/My Drive/cnnoncifar/'\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size), steps_per_epoch = x_train.shape[0]/batch_size, initial_epoch = 30,\n",
        "                    epochs = 60, validation_data =(x_test, y_test), callbacks = [checkpoint,csvlog])\n",
        "model.save_weights(os.path.join(path, '60epochs.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/60\n",
            "390/390 [==============================] - 205s 523ms/step - loss: 0.3386 - accuracy: 0.8813 - val_loss: 0.5455 - val_accuracy: 0.8327\n",
            "Epoch 32/60\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3281 - accuracy: 0.8853 - val_loss: 0.4917 - val_accuracy: 0.8461\n",
            "Epoch 33/60\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3218 - accuracy: 0.8858 - val_loss: 0.4398 - val_accuracy: 0.8573\n",
            "Epoch 34/60\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.3181 - accuracy: 0.8883 - val_loss: 0.5518 - val_accuracy: 0.8365\n",
            "Epoch 35/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.3129 - accuracy: 0.8899 - val_loss: 0.5829 - val_accuracy: 0.8247\n",
            "Epoch 36/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.3045 - accuracy: 0.8934 - val_loss: 0.3996 - val_accuracy: 0.8678\n",
            "Epoch 37/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.3002 - accuracy: 0.8947 - val_loss: 0.6270 - val_accuracy: 0.8200\n",
            "Epoch 38/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.2954 - accuracy: 0.8962 - val_loss: 0.4378 - val_accuracy: 0.8638\n",
            "Epoch 39/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.2892 - accuracy: 0.8991 - val_loss: 0.4421 - val_accuracy: 0.8563\n",
            "Epoch 40/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.2856 - accuracy: 0.8996 - val_loss: 0.4193 - val_accuracy: 0.8676\n",
            "Epoch 41/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.2792 - accuracy: 0.9014 - val_loss: 0.4599 - val_accuracy: 0.8582\n",
            "Epoch 42/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.2695 - accuracy: 0.9039 - val_loss: 0.4209 - val_accuracy: 0.8711\n",
            "Epoch 43/60\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.2662 - accuracy: 0.9068 - val_loss: 0.4567 - val_accuracy: 0.8629\n",
            "Epoch 44/60\n",
            "390/390 [==============================] - 208s 531ms/step - loss: 0.2658 - accuracy: 0.9077 - val_loss: 0.3970 - val_accuracy: 0.8753\n",
            "Epoch 45/60\n",
            "390/390 [==============================] - 207s 531ms/step - loss: 0.2599 - accuracy: 0.9086 - val_loss: 0.4761 - val_accuracy: 0.8521\n",
            "Epoch 46/60\n",
            "390/390 [==============================] - 208s 531ms/step - loss: 0.2550 - accuracy: 0.9099 - val_loss: 0.4949 - val_accuracy: 0.8509\n",
            "Epoch 47/60\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.2586 - accuracy: 0.9098 - val_loss: 0.5405 - val_accuracy: 0.8490\n",
            "Epoch 48/60\n",
            "390/390 [==============================] - 208s 531ms/step - loss: 0.2472 - accuracy: 0.9126 - val_loss: 0.4816 - val_accuracy: 0.8555\n",
            "Epoch 49/60\n",
            "390/390 [==============================] - 207s 531ms/step - loss: 0.2466 - accuracy: 0.9132 - val_loss: 0.4624 - val_accuracy: 0.8631\n",
            "Epoch 50/60\n",
            "390/390 [==============================] - 208s 531ms/step - loss: 0.2386 - accuracy: 0.9161 - val_loss: 0.4368 - val_accuracy: 0.8678\n",
            "Epoch 51/60\n",
            "390/390 [==============================] - 207s 531ms/step - loss: 0.2373 - accuracy: 0.9162 - val_loss: 0.4121 - val_accuracy: 0.8686\n",
            "Epoch 52/60\n",
            "390/390 [==============================] - 208s 531ms/step - loss: 0.2331 - accuracy: 0.9187 - val_loss: 0.4194 - val_accuracy: 0.8688\n",
            "Epoch 53/60\n",
            "390/390 [==============================] - 206s 526ms/step - loss: 0.2302 - accuracy: 0.9198 - val_loss: 0.4925 - val_accuracy: 0.8592\n",
            "Epoch 54/60\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.2281 - accuracy: 0.9197 - val_loss: 0.4327 - val_accuracy: 0.8694\n",
            "Epoch 55/60\n",
            "390/390 [==============================] - 204s 523ms/step - loss: 0.2223 - accuracy: 0.9222 - val_loss: 0.4268 - val_accuracy: 0.8698\n",
            "Epoch 56/60\n",
            "390/390 [==============================] - 211s 539ms/step - loss: 0.2243 - accuracy: 0.9210 - val_loss: 0.4026 - val_accuracy: 0.8775\n",
            "Epoch 57/60\n",
            "390/390 [==============================] - 205s 524ms/step - loss: 0.2190 - accuracy: 0.9222 - val_loss: 0.3832 - val_accuracy: 0.8844\n",
            "Epoch 58/60\n",
            "390/390 [==============================] - 207s 530ms/step - loss: 0.2100 - accuracy: 0.9254 - val_loss: 0.4478 - val_accuracy: 0.8747\n",
            "Epoch 59/60\n",
            "375/390 [===========================>..] - ETA: 7s - loss: 0.2123 - accuracy: 0.9245"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA3jHpNFmwkh",
        "outputId": "700fa5df-7071-4a57-ddab-da80d1cf73a6"
      },
      "source": [
        "model.load_weights('/content/gdrive/MyDrive/cnnoncifar/cifar10_model_save/model-058-0.925400-0.874700.h5')\n",
        "\n",
        "path = 'gdrive/My Drive/cnnoncifar/'\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size), steps_per_epoch = x_train.shape[0]/batch_size, initial_epoch = 58,\n",
        "                    epochs = 100, validation_data =(x_test, y_test), callbacks = [checkpoint,csvlog])\n",
        "model.save_weights(os.path.join(path, '100epochs.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/100\n",
            "390/390 [==============================] - 266s 582ms/step - loss: 0.2071 - accuracy: 0.9270 - val_loss: 0.4066 - val_accuracy: 0.8796\n",
            "Epoch 60/100\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.2085 - accuracy: 0.9263 - val_loss: 0.4008 - val_accuracy: 0.8818\n",
            "Epoch 61/100\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.2085 - accuracy: 0.9263 - val_loss: 0.3849 - val_accuracy: 0.8863\n",
            "Epoch 62/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.2000 - accuracy: 0.9287 - val_loss: 0.4603 - val_accuracy: 0.8674\n",
            "Epoch 63/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.2026 - accuracy: 0.9285 - val_loss: 0.5404 - val_accuracy: 0.8557\n",
            "Epoch 64/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.2030 - accuracy: 0.9277 - val_loss: 0.3928 - val_accuracy: 0.8810\n",
            "Epoch 65/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1926 - accuracy: 0.9313 - val_loss: 0.6280 - val_accuracy: 0.8372\n",
            "Epoch 66/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1964 - accuracy: 0.9295 - val_loss: 0.4520 - val_accuracy: 0.8749\n",
            "Epoch 67/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1919 - accuracy: 0.9320 - val_loss: 0.4563 - val_accuracy: 0.8738\n",
            "Epoch 68/100\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1900 - accuracy: 0.9335 - val_loss: 0.3898 - val_accuracy: 0.8866\n",
            "Epoch 69/100\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1830 - accuracy: 0.9345 - val_loss: 0.6411 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1829 - accuracy: 0.9349 - val_loss: 0.4010 - val_accuracy: 0.8852\n",
            "Epoch 71/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1823 - accuracy: 0.9343 - val_loss: 0.4960 - val_accuracy: 0.8622\n",
            "Epoch 72/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1764 - accuracy: 0.9376 - val_loss: 0.4266 - val_accuracy: 0.8808\n",
            "Epoch 73/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1781 - accuracy: 0.9377 - val_loss: 0.4159 - val_accuracy: 0.8790\n",
            "Epoch 74/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1762 - accuracy: 0.9378 - val_loss: 0.5061 - val_accuracy: 0.8619\n",
            "Epoch 75/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1778 - accuracy: 0.9375 - val_loss: 0.4369 - val_accuracy: 0.8729\n",
            "Epoch 76/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1716 - accuracy: 0.9403 - val_loss: 0.4158 - val_accuracy: 0.8829\n",
            "Epoch 77/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1652 - accuracy: 0.9409 - val_loss: 0.4428 - val_accuracy: 0.8756\n",
            "Epoch 78/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1666 - accuracy: 0.9410 - val_loss: 0.4739 - val_accuracy: 0.8712\n",
            "Epoch 79/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1639 - accuracy: 0.9429 - val_loss: 0.4994 - val_accuracy: 0.8692\n",
            "Epoch 80/100\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1618 - accuracy: 0.9426 - val_loss: 0.4694 - val_accuracy: 0.8718\n",
            "Epoch 81/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1619 - accuracy: 0.9419 - val_loss: 0.4469 - val_accuracy: 0.8826\n",
            "Epoch 82/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1628 - accuracy: 0.9431 - val_loss: 0.3872 - val_accuracy: 0.8921\n",
            "Epoch 83/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1607 - accuracy: 0.9427 - val_loss: 0.3881 - val_accuracy: 0.8884\n",
            "Epoch 84/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1560 - accuracy: 0.9451 - val_loss: 0.3622 - val_accuracy: 0.8983\n",
            "Epoch 85/100\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1548 - accuracy: 0.9441 - val_loss: 0.4590 - val_accuracy: 0.8754\n",
            "Epoch 86/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1541 - accuracy: 0.9462 - val_loss: 0.4220 - val_accuracy: 0.8835\n",
            "Epoch 87/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1516 - accuracy: 0.9457 - val_loss: 0.3835 - val_accuracy: 0.8947\n",
            "Epoch 88/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1472 - accuracy: 0.9477 - val_loss: 0.4406 - val_accuracy: 0.8812\n",
            "Epoch 89/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1490 - accuracy: 0.9475 - val_loss: 0.4865 - val_accuracy: 0.8745\n",
            "Epoch 90/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1507 - accuracy: 0.9460 - val_loss: 0.4925 - val_accuracy: 0.8738\n",
            "Epoch 91/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1445 - accuracy: 0.9490 - val_loss: 0.3943 - val_accuracy: 0.8922\n",
            "Epoch 92/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1472 - accuracy: 0.9465 - val_loss: 0.3601 - val_accuracy: 0.8974\n",
            "Epoch 93/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1403 - accuracy: 0.9500 - val_loss: 0.3710 - val_accuracy: 0.8985\n",
            "Epoch 94/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1385 - accuracy: 0.9508 - val_loss: 0.4378 - val_accuracy: 0.8852\n",
            "Epoch 95/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1395 - accuracy: 0.9515 - val_loss: 0.4358 - val_accuracy: 0.8829\n",
            "Epoch 96/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1401 - accuracy: 0.9506 - val_loss: 0.3969 - val_accuracy: 0.8921\n",
            "Epoch 97/100\n",
            "390/390 [==============================] - 222s 569ms/step - loss: 0.1361 - accuracy: 0.9518 - val_loss: 0.5035 - val_accuracy: 0.8722\n",
            "Epoch 98/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1349 - accuracy: 0.9518 - val_loss: 0.3865 - val_accuracy: 0.8972\n",
            "Epoch 99/100\n",
            "390/390 [==============================] - 216s 553ms/step - loss: 0.1356 - accuracy: 0.9515 - val_loss: 0.3974 - val_accuracy: 0.8908\n",
            "Epoch 100/100\n",
            "390/390 [==============================] - 216s 554ms/step - loss: 0.1337 - accuracy: 0.9516 - val_loss: 0.4682 - val_accuracy: 0.8825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ePSOPJa24xJ",
        "outputId": "7d9153cd-c0be-439a-a143-0bb1c12a0d65"
      },
      "source": [
        "model.load_weights('/content/gdrive/MyDrive/cnnoncifar/cifar10_model_save/model-100-0.951640-0.882500.h5')\n",
        "\n",
        "path = 'gdrive/My Drive/cnnoncifar/'\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size), steps_per_epoch = x_train.shape[0]/batch_size, initial_epoch = 100,\n",
        "                    epochs = 170, validation_data =(x_test, y_test), callbacks = [checkpoint,csvlog])\n",
        "model.save_weights(os.path.join(path, '170epochs.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101/170\n",
            "390/390 [==============================] - 259s 566ms/step - loss: 0.1317 - accuracy: 0.9523 - val_loss: 0.3763 - val_accuracy: 0.8964\n",
            "Epoch 102/170\n",
            "390/390 [==============================] - 214s 549ms/step - loss: 0.1298 - accuracy: 0.9544 - val_loss: 0.4371 - val_accuracy: 0.8885\n",
            "Epoch 103/170\n",
            "390/390 [==============================] - 215s 549ms/step - loss: 0.1334 - accuracy: 0.9531 - val_loss: 0.4418 - val_accuracy: 0.8836\n",
            "Epoch 104/170\n",
            "390/390 [==============================] - 214s 548ms/step - loss: 0.1302 - accuracy: 0.9527 - val_loss: 0.4042 - val_accuracy: 0.8973\n",
            "Epoch 105/170\n",
            "390/390 [==============================] - 214s 548ms/step - loss: 0.1237 - accuracy: 0.9557 - val_loss: 0.4946 - val_accuracy: 0.8764\n",
            "Epoch 106/170\n",
            "390/390 [==============================] - 214s 549ms/step - loss: 0.1227 - accuracy: 0.9561 - val_loss: 0.4145 - val_accuracy: 0.8940\n",
            "Epoch 107/170\n",
            "390/390 [==============================] - 214s 549ms/step - loss: 0.1220 - accuracy: 0.9577 - val_loss: 0.3664 - val_accuracy: 0.9007\n",
            "Epoch 108/170\n",
            "390/390 [==============================] - 221s 564ms/step - loss: 0.1277 - accuracy: 0.9542 - val_loss: 0.3625 - val_accuracy: 0.8996\n",
            "Epoch 109/170\n",
            "390/390 [==============================] - 214s 549ms/step - loss: 0.1208 - accuracy: 0.9578 - val_loss: 0.3863 - val_accuracy: 0.9003\n",
            "Epoch 110/170\n",
            "390/390 [==============================] - 214s 549ms/step - loss: 0.1224 - accuracy: 0.9561 - val_loss: 0.4434 - val_accuracy: 0.8861\n",
            "Epoch 111/170\n",
            "390/390 [==============================] - 215s 549ms/step - loss: 0.1206 - accuracy: 0.9580 - val_loss: 0.4337 - val_accuracy: 0.8891\n",
            "Epoch 112/170\n",
            "390/390 [==============================] - 214s 549ms/step - loss: 0.1180 - accuracy: 0.9586 - val_loss: 0.3978 - val_accuracy: 0.8922\n",
            "Epoch 113/170\n",
            "390/390 [==============================] - 214s 548ms/step - loss: 0.1175 - accuracy: 0.9576 - val_loss: 0.3961 - val_accuracy: 0.8952\n",
            "Epoch 114/170\n",
            "390/390 [==============================] - 220s 564ms/step - loss: 0.1152 - accuracy: 0.9593 - val_loss: 0.4485 - val_accuracy: 0.8886\n",
            "Epoch 115/170\n",
            "390/390 [==============================] - 215s 550ms/step - loss: 0.1207 - accuracy: 0.9570 - val_loss: 0.4182 - val_accuracy: 0.8960\n",
            "Epoch 116/170\n",
            "390/390 [==============================] - 214s 548ms/step - loss: 0.1156 - accuracy: 0.9596 - val_loss: 0.4677 - val_accuracy: 0.8847\n",
            "Epoch 117/170\n",
            "390/390 [==============================] - 214s 548ms/step - loss: 0.1180 - accuracy: 0.9579 - val_loss: 0.5786 - val_accuracy: 0.8594\n",
            "Epoch 118/170\n",
            "278/390 [====================>.........] - ETA: 57s - loss: 0.1132 - accuracy: 0.9594"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9geH8-lefPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be52e480-df6c-45e9-d17f-01c1d815924d"
      },
      "source": [
        "model.load_weights('/content/gdrive/MyDrive/cnnoncifar/cifar10_model_save/model-117-0.957860-0.859400.h5')\n",
        "path = 'gdrive/My Drive/cnnoncifar/'\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size), steps_per_epoch = x_train.shape[0]/batch_size, initial_epoch = 117,\n",
        "                    epochs = 170, validation_data =(x_test, y_test), callbacks = [checkpoint,csvlog])\n",
        "model.save_weights(os.path.join(path, '170epochs.h5'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 118/170\n",
            "390/390 [==============================] - 261s 571ms/step - loss: 0.1101 - accuracy: 0.9606 - val_loss: 0.4266 - val_accuracy: 0.8918\n",
            "Epoch 119/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1146 - accuracy: 0.9594 - val_loss: 0.3557 - val_accuracy: 0.9037\n",
            "Epoch 120/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1103 - accuracy: 0.9610 - val_loss: 0.3594 - val_accuracy: 0.9048\n",
            "Epoch 121/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1112 - accuracy: 0.9603 - val_loss: 0.4285 - val_accuracy: 0.8923\n",
            "Epoch 122/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1107 - accuracy: 0.9611 - val_loss: 0.3594 - val_accuracy: 0.9033\n",
            "Epoch 123/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1059 - accuracy: 0.9628 - val_loss: 0.3718 - val_accuracy: 0.9029\n",
            "Epoch 124/170\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.1027 - accuracy: 0.9636 - val_loss: 0.3805 - val_accuracy: 0.8987\n",
            "Epoch 125/170\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.1098 - accuracy: 0.9613 - val_loss: 0.4183 - val_accuracy: 0.8956\n",
            "Epoch 126/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1125 - accuracy: 0.9605 - val_loss: 0.3563 - val_accuracy: 0.9035\n",
            "Epoch 127/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1083 - accuracy: 0.9617 - val_loss: 0.3801 - val_accuracy: 0.8988\n",
            "Epoch 128/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1061 - accuracy: 0.9621 - val_loss: 0.3781 - val_accuracy: 0.9013\n",
            "Epoch 129/170\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.1020 - accuracy: 0.9640 - val_loss: 0.4838 - val_accuracy: 0.8833\n",
            "Epoch 130/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1043 - accuracy: 0.9629 - val_loss: 0.4289 - val_accuracy: 0.8951\n",
            "Epoch 131/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.1001 - accuracy: 0.9640 - val_loss: 0.3525 - val_accuracy: 0.9086\n",
            "Epoch 132/170\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.1022 - accuracy: 0.9644 - val_loss: 0.4281 - val_accuracy: 0.8933\n",
            "Epoch 133/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0996 - accuracy: 0.9658 - val_loss: 0.4067 - val_accuracy: 0.9008\n",
            "Epoch 134/170\n",
            "390/390 [==============================] - 224s 573ms/step - loss: 0.0967 - accuracy: 0.9657 - val_loss: 0.3942 - val_accuracy: 0.9020\n",
            "Epoch 135/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1017 - accuracy: 0.9643 - val_loss: 0.3585 - val_accuracy: 0.9074\n",
            "Epoch 136/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.1003 - accuracy: 0.9646 - val_loss: 0.4464 - val_accuracy: 0.8886\n",
            "Epoch 137/170\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0986 - accuracy: 0.9659 - val_loss: 0.4133 - val_accuracy: 0.8965\n",
            "Epoch 138/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0949 - accuracy: 0.9668 - val_loss: 0.5549 - val_accuracy: 0.8706\n",
            "Epoch 139/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0950 - accuracy: 0.9669 - val_loss: 0.4177 - val_accuracy: 0.8975\n",
            "Epoch 140/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0968 - accuracy: 0.9651 - val_loss: 0.4429 - val_accuracy: 0.8914\n",
            "Epoch 141/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0943 - accuracy: 0.9671 - val_loss: 0.4340 - val_accuracy: 0.8943\n",
            "Epoch 142/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0938 - accuracy: 0.9666 - val_loss: 0.4741 - val_accuracy: 0.8903\n",
            "Epoch 143/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0916 - accuracy: 0.9680 - val_loss: 0.3351 - val_accuracy: 0.9140\n",
            "Epoch 144/170\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0949 - accuracy: 0.9672 - val_loss: 0.4273 - val_accuracy: 0.8961\n",
            "Epoch 145/170\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0941 - accuracy: 0.9670 - val_loss: 0.3592 - val_accuracy: 0.9056\n",
            "Epoch 146/170\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0924 - accuracy: 0.9680 - val_loss: 0.3545 - val_accuracy: 0.9068\n",
            "Epoch 147/170\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0933 - accuracy: 0.9671 - val_loss: 0.4598 - val_accuracy: 0.8914\n",
            "Epoch 148/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0883 - accuracy: 0.9689 - val_loss: 0.3479 - val_accuracy: 0.9121\n",
            "Epoch 149/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0893 - accuracy: 0.9687 - val_loss: 0.4738 - val_accuracy: 0.8864\n",
            "Epoch 150/170\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0890 - accuracy: 0.9691 - val_loss: 0.3577 - val_accuracy: 0.9106\n",
            "Epoch 151/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0874 - accuracy: 0.9696 - val_loss: 0.4714 - val_accuracy: 0.8898\n",
            "Epoch 152/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0889 - accuracy: 0.9686 - val_loss: 0.3812 - val_accuracy: 0.9018\n",
            "Epoch 153/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0860 - accuracy: 0.9695 - val_loss: 0.4595 - val_accuracy: 0.8907\n",
            "Epoch 154/170\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0863 - accuracy: 0.9695 - val_loss: 0.4402 - val_accuracy: 0.8963\n",
            "Epoch 155/170\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0834 - accuracy: 0.9700 - val_loss: 0.3891 - val_accuracy: 0.9071\n",
            "Epoch 156/170\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0829 - accuracy: 0.9714 - val_loss: 0.3793 - val_accuracy: 0.9029\n",
            "Epoch 157/170\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0855 - accuracy: 0.9696 - val_loss: 0.3976 - val_accuracy: 0.9040\n",
            "Epoch 158/170\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0826 - accuracy: 0.9707 - val_loss: 0.4268 - val_accuracy: 0.8970\n",
            "Epoch 159/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0874 - accuracy: 0.9686 - val_loss: 0.4545 - val_accuracy: 0.8959\n",
            "Epoch 160/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0835 - accuracy: 0.9706 - val_loss: 0.4577 - val_accuracy: 0.8917\n",
            "Epoch 161/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0851 - accuracy: 0.9704 - val_loss: 0.4176 - val_accuracy: 0.8987\n",
            "Epoch 162/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0805 - accuracy: 0.9710 - val_loss: 0.3944 - val_accuracy: 0.9046\n",
            "Epoch 163/170\n",
            "390/390 [==============================] - 223s 572ms/step - loss: 0.0834 - accuracy: 0.9708 - val_loss: 0.4053 - val_accuracy: 0.9010\n",
            "Epoch 164/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0802 - accuracy: 0.9720 - val_loss: 0.3823 - val_accuracy: 0.9068\n",
            "Epoch 165/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.3682 - val_accuracy: 0.9096\n",
            "Epoch 166/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0784 - accuracy: 0.9724 - val_loss: 0.4096 - val_accuracy: 0.8986\n",
            "Epoch 167/170\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0765 - accuracy: 0.9730 - val_loss: 0.4288 - val_accuracy: 0.9057\n",
            "Epoch 168/170\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.4138 - val_accuracy: 0.9043\n",
            "Epoch 169/170\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 0.3945 - val_accuracy: 0.9046\n",
            "Epoch 170/170\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0766 - accuracy: 0.9732 - val_loss: 0.4235 - val_accuracy: 0.8998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QuWn-obE2u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d317a855-14a6-4b36-8671-50cac242d87f"
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.backend.set_value(model.optimizer.momentum, 0.7)\n",
        "keras.backend.set_value(model.optimizer.lr, 0.001)\n",
        "model.load_weights('/content/gdrive/MyDrive/cnnoncifar/cifar10_model_save/model-170-0.973180-0.899800.h5')\n",
        "path = 'gdrive/My Drive/cnnoncifar/'\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size), steps_per_epoch = x_train.shape[0]/batch_size, initial_epoch = 170,\n",
        "                    epochs = 210, validation_data =(x_test, y_test), callbacks = [checkpoint,csvlog])\n",
        "model.save_weights(os.path.join(path, '210epochs.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 171/210\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 0.3551 - val_accuracy: 0.9145\n",
            "Epoch 172/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0645 - accuracy: 0.9769 - val_loss: 0.3490 - val_accuracy: 0.9162\n",
            "Epoch 173/210\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0602 - accuracy: 0.9796 - val_loss: 0.3467 - val_accuracy: 0.9177\n",
            "Epoch 174/210\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0567 - accuracy: 0.9803 - val_loss: 0.3451 - val_accuracy: 0.9189\n",
            "Epoch 175/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 0.3409 - val_accuracy: 0.9192\n",
            "Epoch 176/210\n",
            "390/390 [==============================] - 217s 554ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.3397 - val_accuracy: 0.9196\n",
            "Epoch 177/210\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0553 - accuracy: 0.9808 - val_loss: 0.3392 - val_accuracy: 0.9194\n",
            "Epoch 178/210\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0525 - accuracy: 0.9825 - val_loss: 0.3391 - val_accuracy: 0.9201\n",
            "Epoch 179/210\n",
            "390/390 [==============================] - 223s 571ms/step - loss: 0.0550 - accuracy: 0.9817 - val_loss: 0.3377 - val_accuracy: 0.9204\n",
            "Epoch 180/210\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0512 - accuracy: 0.9819 - val_loss: 0.3373 - val_accuracy: 0.9206\n",
            "Epoch 181/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0518 - accuracy: 0.9818 - val_loss: 0.3373 - val_accuracy: 0.9202\n",
            "Epoch 182/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 0.3353 - val_accuracy: 0.9211\n",
            "Epoch 183/210\n",
            "390/390 [==============================] - 217s 555ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.3370 - val_accuracy: 0.9209\n",
            "Epoch 184/210\n",
            "390/390 [==============================] - 223s 571ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.3371 - val_accuracy: 0.9209\n",
            "Epoch 185/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.3345 - val_accuracy: 0.9211\n",
            "Epoch 186/210\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.3347 - val_accuracy: 0.9206\n",
            "Epoch 187/210\n",
            "390/390 [==============================] - 217s 557ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 0.3348 - val_accuracy: 0.9204\n",
            "Epoch 188/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 0.3330 - val_accuracy: 0.9206\n",
            "Epoch 189/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.3341 - val_accuracy: 0.9212\n",
            "Epoch 190/210\n",
            "390/390 [==============================] - 217s 556ms/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 0.3328 - val_accuracy: 0.9210\n",
            "Epoch 191/210\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0469 - accuracy: 0.9836 - val_loss: 0.3343 - val_accuracy: 0.9206\n",
            "Epoch 192/210\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.3345 - val_accuracy: 0.9204\n",
            "Epoch 193/210\n",
            "390/390 [==============================] - 218s 557ms/step - loss: 0.0466 - accuracy: 0.9843 - val_loss: 0.3326 - val_accuracy: 0.9211\n",
            "Epoch 194/210\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.3338 - val_accuracy: 0.9206\n",
            "Epoch 195/210\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 0.3331 - val_accuracy: 0.9209\n",
            "Epoch 196/210\n",
            "390/390 [==============================] - 218s 558ms/step - loss: 0.0451 - accuracy: 0.9846 - val_loss: 0.3338 - val_accuracy: 0.9206\n",
            "Epoch 197/210\n",
            "390/390 [==============================] - 218s 559ms/step - loss: 0.0455 - accuracy: 0.9847 - val_loss: 0.3339 - val_accuracy: 0.9206\n",
            "Epoch 198/210\n",
            "390/390 [==============================] - 218s 559ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.3337 - val_accuracy: 0.9202\n",
            "Epoch 199/210\n",
            "390/390 [==============================] - 218s 559ms/step - loss: 0.0457 - accuracy: 0.9847 - val_loss: 0.3339 - val_accuracy: 0.9205\n",
            "Epoch 200/210\n",
            " 34/390 [=>............................] - ETA: 3:06 - loss: 0.0555 - accuracy: 0.9816"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXQnKRHlVlBD"
      },
      "source": [
        "**Observation**\n",
        "\n",
        "We have used cifar10 dataset and did one hot encoding. As per referenece assignment, used dense block,transition block and output_layer.\n",
        "\n",
        "To convet on cifar10 dataset, we have used 2D Convolutional neural network and top of that, we have applied dense block to create first block,and for first transition, we have applied transition block on top of first block. Similarly, We created second block,second transition and third block, third transition. On top of last block, we have applied output layer and create the model.\n",
        "\n",
        "We have used image augmentation technique, and fit train data. We have used categorical_crossentropy as loss function and SGD optimizer with 0.7 momentum and trained the model using metrics \"accuracy\". \n",
        "We have trained by 300 epochs and got test accuracy 90%+."
      ]
    }
  ]
}